# -*- coding: utf-8 -*-
"""Flothers AI4CS task clean.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1EMWEJx34GJylsAtlDRVNCrigKEJbvePo
"""

!rm -rf flothers_malware_task

!git clone https://github.com/asim97/flothers_malware_task.git

!wget https://raw.githubusercontent.com/Yara-Rules/rules/master/packers/peid.yar
!wget https://raw.githubusercontent.com/Yara-Rules/rules/master/packers/packer.yar
!wget https://raw.githubusercontent.com/Yara-Rules/rules/master/crypto/crypto_signatures.yar
!wget https://raw.githubusercontent.com/Yara-Rules/rules/master/capabilities/capabilities.yar
!wget https://raw.githubusercontent.com/Yara-Rules/rules/master/antidebug_antivm/antidebug_antivm.yar

!pip install yara-python
!pip install pefile
!pip install -q latextable

"""# Import libs"""

from tabulate import tabulate
from texttable import Texttable

import latextable
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import pickle
import itertools

import pefile
import yara
import re

from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, plot_confusion_matrix,f1_score
from sklearn.metrics import classification_report, accuracy_score
from sklearn.base import is_classifier

from sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier
from sklearn.tree import DecisionTreeClassifier
from xgboost import XGBClassifier
from sklearn.naive_bayes import GaussianNB
# from sklearn.ensemble import StackingClassifier
# from sklearn.ensemble import VotingClassifier
from sklearn.linear_model import SGDClassifier
from sklearn.ensemble import BaggingClassifier
from sklearn.neural_network import MLPClassifier

"""#Functions"""

#function for PE
def pe_list_imported_DLLs(hash_var):
  try:
    pe = pefile.PE(files_path+hash_var)
    # print("[*] Listing imported DLLs...")
    list_dll=[]
    for entry in pe.DIRECTORY_ENTRY_IMPORT:
      list_dll.append(entry.dll.decode('utf-8'))
    return list_dll
  except:
    list_dll=[]
    return list_dll


def pe_list_imported_DLLs_imports(hash_var,dll_name):
  try:
    pe = pefile.PE(files_path+hash_var)
    # print("[*] Listing imported DLLs imports...")
    list_imports=[]
    for entry in pe.DIRECTORY_ENTRY_IMPORT:
      temp_dll_name = entry.dll.decode('utf-8')
      if temp_dll_name == dll_name:
          for func in entry.imports:
              list_imports.append(func.name.decode('utf-8')) 
    return list_imports
  except:
    list_imports=[]
    return list_imports

def pe_sections_name(hash_var):
  try:
    pe = pefile.PE(files_path+hash_var)
    list_section=[]
    for section in pe.sections:
      # print(section.Name.decode('utf-8'))
      try:
        list_section.append(re.sub(r'\x00', '',section.Name.decode('utf-8'))) #remove \x00 from the section name
      except:
        list_section.append('faild')

    return list_section
  except:
    list_section=[]
    return list_section

def add_feature_PE(dataframe):
  # for index_rule in range(len(rules)):
  #adding sections_name
  feature_list_sections_name=[]
  for index_hash in list(dataframe['hash']):
    result=pe_sections_name(index_hash)
    feature_list_sections_name.append(result)
  dataframe['sections_name_feature']=feature_list_sections_name

  #adding list_imported_DLLs
  feature_list_dll=[]
  for index_hash in list(dataframe['hash']):
    result=pe_list_imported_DLLs(index_hash)
    feature_list_dll.append(result)
  dataframe['imported_DLLs_feature']=feature_list_dll
  
  #(this section takes very long time)
  # #adding list_imported_DLLs_imports
  # feature_list_dll_import=[]
  # for index_hash in list(dataframe['hash']):
  #   for index_dll in feature_list_dll:
  #     result = pe_list_imported_DLLs_imports(index_hash,index_dll)
  #     feature_list_dll_import.append(result)
  # dataframe['imported_DLLs_imports_feature']=feature_list_dll_import

  return dataframe

#function for genrating features from yar rules
def add_feature_yara(dataframe,rules,rules_names):
  for index_rule in range(len(rules)):
    feature_list=[]
    for index_hash in list(dataframe['hash']):
      result=rule_scan_hash(index_hash,rules[index_rule])
      feature_list.append(result)
    dataframe[rules_names[index_rule]+'_feature']=feature_list

def rule_scan_hash(hash_var,rule):
  try:
    return rule.match(files_path+hash_var)
  except:
    return []

#function for Printing the Detailed Metrics Report
def print_table_latex(rows):
  report=[]
  report.append(["Metrics","Value"])
  report.append(["Sensitivity",rows[0]])
  report.append(["Specificity",rows[1]])
  report.append(["Precision",rows[2]])
  report.append(["Negative Predictive Value",rows[3]])
  report.append(["False Positive Rate",rows[4]])
  report.append(["False Discovery Rate",rows[5]])
  report.append(["False Negative Rate",rows[6]])
  report.append(["Accuracy",rows[7]])
  report.append(["F1-Score",rows[8]])
  report.append(["Matthews Correlation Coefficient",rows[9]])

  table = Texttable(max_width=0)
  table.set_cols_align(["c"] * 2)
  table.set_precision(5)
  table.set_deco(Texttable.HEADER | Texttable.VLINES)
  table.add_rows(report)

  print(table.draw())

def model_results(classifier,X_train, y_train, X_test, y_test):
  plt.rcParams.update({'font.size': 14}) 
  #training the model
  classifier.fit(X_train, y_train)
  
  #Predicting the Test set results
  y_pred = classifier.predict(X_test)

  print('\nPlotting Confusion Matrix:' )
  plot_confusion_matrix(classifier, X_test, y_test,values_format="d")  
  plt.show()

  classifier_accuracy=accuracy_score(y_test, y_pred)*100
  print('Accuracy of the model: {:.2f} %' .format(classifier_accuracy))

  classifier_f1_score=f1_score(y_test, y_pred)*100
  print('f1_score of the model: {:.2f} %' .format(classifier_f1_score))

  print('\nClassification Report:\n' )
  print(classification_report(y_test, y_pred,zero_division=0))
  print('\nDetailed Report :\n')
  report_dt=detailed_report(y_test, y_pred)
  print_table_latex(list(report_dt.values()))
  return classifier_accuracy,classifier_f1_score


def detailed_report(y_true, y_pred):
  report = {}
  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()
  tpr = tp / (tp + fn)
  spc = tn / (fp + tn)
  ppv = tp / (tp + fp)
  npv = tn / (tn + fn)
  fpr = fp / (fp + tn)
  fdr = fp / (fp + tp)
  fnr = fn / (fn + tp)
  acc = (tp + tn) / (fp + tp + fn + tn)
  f1 = (2 * tp) / ((2 * tp) + fp + fn)
  mcc = ((tp * tn) - (fp * fn)) / np.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn))
  report["Sensitivity"] = tpr 
  report["Specificity"] = spc
  report["Precision"] = ppv
  report["Negative Predictive Value"] = npv
  report["False Positive Rate"] = fpr
  report["False Discovery Rate"] = fdr
  report["False Negative Rate"] = fnr
  report["Accuracy"] = acc
  report["F1-Score"] = f1
  report["Matthews Correlation Coefficient"] = mcc
  return report

#function for geting features list
def get_new_columns(colum_values):
  #get unige values of the colum
  newlist=[]
  for x in itertools.chain.from_iterable(np.unique(colum_values)):
    if x not in newlist:
        newlist.append(x)
  newlist = [str(s) for s in newlist]
  return newlist

#function for one-hot encoding features list
def encode_lists(colum_values):
  newlist = get_new_columns(colum_values)
  #one hot encode 
  list_indexs=[]
  for x in colum_values:
    list_zero=[0]*len(newlist)
    if len(colum_values)>0:
      for i in range(len(x)):
        index = newlist.index(str(x[i]))
        list_zero[index]=1
    list_indexs.append(list_zero)
  newdf=pd.DataFrame(list_indexs,columns=newlist) 
  return newdf

"""#read dataset"""

dataset=pd.read_csv('/content/flothers_malware_task/final_full_dataset_balanced.csv') #type 0==benign | 1==malware

# show the imbalance in data
plt.rcParams["figure.figsize"] = [7,5]
plt.rcParams["figure.autolayout"] = True
ax = sns.countplot(x="class", data=dataset)
ax.set_xticklabels(['BENIGN','MALICIOUS'])
ax.set_title('Labels count and Percentage in the cleaned dataset', fontsize=12)
for p in ax.patches:
    ax.annotate('{}\n{:.2f} %'.format(p.get_height(),p.get_height()/len(dataset)*100),
                (p.get_x()+0.4, p.get_height()-(p.get_height()/10)),
                ha='center', va='top', color='white', size=14)
plt.show()

"""#yara rules"""

#configs for yara rules
#Path to the folder containing downloaded files in the first part
rules_path = '/content/'
files_path = '/content/flothers_malware_task/Files/'
#Read yara rules files
peid_rules = yara.compile(rules_path + 'peid.yar')
packer_rules = yara.compile(rules_path + 'packer.yar')
crypto_rules = yara.compile(rules_path + 'crypto_signatures.yar')
antidebug_antivm_rules = yara.compile(rules_path + 'antidebug_antivm.yar')
capabilities_rules = yara.compile(rules_path + 'capabilities.yar')
#rules lists are here 
rules_list=[peid_rules,packer_rules,crypto_rules,
            antidebug_antivm_rules,capabilities_rules]
rules_names_list=["peid_rules","packer_rules","crypto_rules",
                  "antidebug_antivm_rules","capabilities_rules"]

add_feature_yara(dataset,rules_list,rules_names_list)

dataset=add_feature_PE(dataset)

display(dataset)

"""#Encoding the Features"""

#appling encoding for all coulmns
for col in dataset.columns[2:]:
  if col == dataset.columns[2]:   
    colum_values=dataset[col].values
    features_df=encode_lists(colum_values)
  else:
    colum_values=dataset[col].values
    features_df=pd.concat([features_df, encode_lists(colum_values)], axis=1)

display(features_df)
# features_df.to_csv("features_df.csv")

"""# Splitting Dataset"""

rs=0
y=dataset[dataset.columns[1]].values
X=features_df.iloc[:,:].values
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)

print("Training")
print(f"Number of 1s (MALICIOUS): {np.sum(y_train)}")
print(f"Number of 0s (BENIGN)   : {len(y_train)-np.sum(y_train)}")

print("Validation")
print(f"Number of 1s (MALICIOUS): {np.sum(y_test)}")
print(f"Number of 0s (BENIGN)   : {len(y_test)-np.sum(y_test)}")

#plot the split dataset (train + test)
cars = ['Training', 'Validation']
data = [(np.sum(y_train))+(len(y_train)-np.sum(y_train)),
        (np.sum(y_test))+(len(y_test)-np.sum(y_test))]
plt.rcParams.update({'font.size': 15})

 
# Creating explode data
explode = (0.1, 0.1)
 
# Creating color parameters
colors = ( "yellow", "cyan")
 
# Wedge properties
wp = { 'linewidth' : 1, 'edgecolor' : "green" }
 
# Creating autocpt arguments
def func(pct):
  if pct>50 :
    absolute = int(len(y_train)-np.sum(y_train))
    absolute2 = int(np.sum(y_train))
  else:
    absolute = int(len(y_test)-np.sum(y_test))
    absolute2 = int(np.sum(y_test))
  return "{:.1f}%\n(BENIGN :{:d})\n    (MALICIOUS :{:d})".format(pct, absolute,absolute2)
 
# Creating plot
fig, ax = plt.subplots(figsize =(10, 7))
wedges, texts, autotexts = ax.pie(data,
                                  autopct = lambda pct: func(pct),
                                  explode = explode,
                                  labels = cars,
                                  shadow = True,
                                  colors = colors,
                                  startangle = 90,
                                  wedgeprops = wp,
                                  textprops = dict(color ="black"))
 
# Adding legend
ax.legend(wedges, cars,
          title ="Dataset Split",
          loc ="center left",
          bbox_to_anchor =(1, 0, 0.5, 1))
 
plt.setp(autotexts, size = 12, weight ="bold")
 
# show plot
plt.show()

"""# Classifiers"""

classifier_SGDC=SGDClassifier(loss= 'log',max_iter=1000,learning_rate='optimal',
                               eta0=0.9, power_t=0.5, tol=0.1,
                               n_iter_no_change=9,random_state=rs)
classifier_accuracy_SGDC,classifier_f1_score_SGDC = model_results(classifier_SGDC,X_train, y_train, X_test, y_test)

classifier_DTC=DecisionTreeClassifier(class_weight=None, criterion="entropy",
                                  max_depth=70,
                                  # max_features=1000,
                                  min_samples_leaf=1, min_samples_split=10,
                                  min_weight_fraction_leaf=0.0, random_state=rs, splitter="best")

print('\n'+"="*10 +" Decision Tree Classifier "+"="*10 +'\n' )
classifier_accuracy_DTC,classifier_f1_score_DTC = model_results(classifier_DTC,X_train, y_train, X_test, y_test)

classifier_RF = RandomForestClassifier(criterion='entropy', max_depth=70,
                          min_samples_split=10,
                          n_estimators=100, n_jobs=-1,
                          random_state=rs, verbose=0)

print('\n'+"="*10 +" Random Forest Classifier "+"="*10 +'\n' )
classifier_accuracy_RF,classifier_f1_score_RF = model_results(classifier_RF,X_train, y_train, X_test, y_test)

classifier_AB = AdaBoostClassifier(n_estimators = 50, random_state = rs)

print('\n'+"="*10 +"== Ada Boost Classifier =="+"="*10 +'\n')
classifier_accuracy_AB,classifier_f1_score_AB = model_results(classifier_AB,X_train, y_train, X_test, y_test)

classifier_NB = GaussianNB(var_smoothing=2)

print('\n'+"="*10 +"== Gaussian Naive Bayes =="+"="*10 +'\n' )
classifier_accuracy_NB,classifier_f1_score_NB = model_results(classifier_NB,X_train, y_train, X_test, y_test)

# %%time
classifier_XGB = XGBClassifier(max_depth=50, learning_rate=0.9, n_estimators=100, verbosity=0,
                               objective='binary:logistic', booster='gbtree',
                               n_jobs=1,base_score=0.5, num_feature=15,random_state=rs)

print('\n'+"="*10 +"=== XGBoost Classifier ==="+"="*10 +'\n' )
classifier_accuracy_XGB,classifier_f1_score_XGB = model_results(classifier_XGB,X_train, y_train, X_test, y_test)

classifier_MLP = MLPClassifier(random_state=rs, hidden_layer_sizes=(100, ),
                               activation='logistic',learning_rate="constant",verbose=0, max_iter=100)

print('\n'+"="*10 +"===== MLP Classifier ====="+"="*10 +'\n' )
classifier_accuracy_MLP,classifier_f1_score_MLP = model_results(classifier_MLP,X_train, y_train, X_test, y_test)

#Exporting Models
newlist=list(features_df.columns)

model_name = [ 'XGBoost', 'Random Forest', 'Decision Tree', 'AdaBoost', 'Naive Bayes','SGD','MLP']

model_list   =[classifier_XGB,classifier_RF,classifier_DTC,classifier_AB,
               classifier_NB,classifier_SGDC,classifier_MLP]
f1_score_all =[classifier_f1_score_XGB,classifier_f1_score_RF,classifier_f1_score_DTC,classifier_f1_score_AB,
               classifier_f1_score_NB,classifier_f1_score_SGDC,classifier_f1_score_MLP]
accuracy_all =[classifier_accuracy_XGB,classifier_accuracy_RF,classifier_accuracy_DTC,classifier_accuracy_AB,
               classifier_accuracy_NB,classifier_accuracy_SGDC,classifier_accuracy_MLP]
# Saving the the models and the labelencoder data:
with open('malware_models.pkl', 'wb') as f: 
    pickle.dump([model_name, model_list, f1_score_all, accuracy_all, newlist], f)

"""#Testing Production Enviroment"""

test_dataset=pd.read_csv('/content/flothers_malware_task/Files/test_df.csv') #type 0==benign | 1==malware

add_feature_yara(test_dataset,rules_list,rules_names_list)
test_dataset=add_feature_PE(test_dataset)

# display(test_dataset)
# #appling encoding for all coulmns

for col in test_dataset.columns[2:]:  #every column after 'hash' column
  if col == test_dataset.columns[2]:   
    colum_values=test_dataset[col].values
    features_df_test=encode_lists(colum_values)
  else:
    colum_values=test_dataset[col].values
    features_df_test=pd.concat([features_df_test, encode_lists(colum_values)], axis=1)

#one-hot encode the dataset
newlist=list(features_df.columns)
newlist_test=list(features_df_test.columns)
# print(newlist)
features_to_pridict=[]
for x in range(len(features_df_test)):
  list_zero=[0]*len(newlist)
  for col in newlist_test:
    if col in newlist:
      result=list(features_df_test[col].values)[x]
      index = newlist.index(col)
      list_zero[index]=result
  features_to_pridict.append(list_zero)

accuracy_all_test=[]
for model in range(len(model_list)):
  pred=model_list[model].predict(features_to_pridict)
  print(f"{model_name[model]} detected: {np.sum(pred)/len(pred)*100}%")
  accuracy_all_test.append(np.sum(pred)/len(pred)*100)

"""#Performance Ploting """

fig = plt.figure(figsize = (15, 5))
plt.rcParams.update({'font.size': 16})

ax = fig.add_axes([0,0,1,1])
ax.bar(model_name,accuracy_all,width=0.4)
for index,data in enumerate(accuracy_all):
    plt.text(x=index-0.2 , y =data+0.5 , s="{:.2f}%".format(data) , fontdict=dict(fontsize=16))
plt.title('Accuracy Comparsions', fontsize=18)
plt.ylabel("Accuracy %", fontsize=18)
plt.ylim(min(accuracy_all)-5,max(accuracy_all)+5)
plt.show()

fig = plt.figure(figsize = (15, 5))
plt.rcParams.update({'font.size': 16})

ax = fig.add_axes([0,0,1,1])
ax.bar(model_name,f1_score_all,width=0.4)
for index,data in enumerate(f1_score_all):
    plt.text(x=index-0.2 , y =data+0.5 , s="{:.2f}%".format(data) , fontdict=dict(fontsize=16))
plt.title('F1 score Comparsions', fontsize=18)
plt.ylabel("F1 score %", fontsize=18)
plt.ylim(min(f1_score_all)-5,max(f1_score_all)+5)
plt.show()

#ploting the accuracy comparsions between all models of Malware Detection
fig = plt.figure(figsize = (15, 5))
plt.rcParams.update({'font.size': 16})

ax = fig.add_axes([0,0,1,1])
ax.bar(model_name,accuracy_all_test,width=0.4)
for index,data in enumerate(accuracy_all_test):
    plt.text(x=index-0.2 , y =data+0.5 , s="{:.2f}%".format(data) , fontdict=dict(fontsize=16))
plt.title('Malware Detection Accuracy Comparsions', fontsize=18)
plt.ylabel("Accuracy %", fontsize=18)
plt.ylim(min(accuracy_all_test)-5,max(accuracy_all_test)+3)
plt.show()

#TODO: plot execution time